{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.5.4 64-bit ('venv')",
   "display_name": "Python 3.5.4 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "58849dcd5f0339abeff79dbd15f3e6d31c296ea9f6c899717bc0c2d8ef60a9b9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Auto detection to main + 4 cropped images\n",
    "**Pipeline:**\n",
    "\n",
    "1. Load cropped image csv file\n",
    "2. Apply prediction\n",
    "3. Save prediction result back to csv file\n",
    "* pred_value\n",
    "* pred_cat\n",
    "* pred_bbox"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "from keras.models import load_model\n",
    "# from utils.utils import *\n",
    "# from utils.bbox import *\n",
    "# from utils.image import load_image_pixels\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import torchvision.transforms.functional as TF\n",
    "import PIL\n",
    "import os\n",
    "import json \n",
    "from urllib.request import urlretrieve\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image directory\n",
    "projectDir=os.getcwd()\n",
    "dataDir='.'\n",
    "dataType='val2017'\n",
    "imageDir='{}/images/'.format(dataDir)\n",
    "annFile='{}/images/{}_selected/annotations/instances_{}.json'.format(dataDir,dataType,dataType)"
   ]
  },
  {
   "source": [
    "## Utilities"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "        self.objness = objness\n",
    "        self.classes = classes\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "\n",
    "        return self.label\n",
    "\n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    "\n",
    "        return self.score\n",
    "\n",
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
    "    grid_h, grid_w = netout.shape[:2]\n",
    "    nb_box = 3\n",
    "    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
    "    nb_class = netout.shape[-1] - 5\n",
    "    boxes = []\n",
    "    netout[..., :2]  = _sigmoid(netout[..., :2])\n",
    "    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
    "    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    "\n",
    "    for i in range(grid_h*grid_w):\n",
    "        row = i // grid_w\n",
    "        col = i % grid_w\n",
    "        for b in range(nb_box):\n",
    "            # 4th element is objectness score\n",
    "            objectness = netout[int(row)][int(col)][b][4]\n",
    "            if(objectness.all() <= obj_thresh): continue\n",
    "            # first 4 elements are x, y, w, and h\n",
    "            x, y, w, h = netout[int(row)][int(col)][b][:4]\n",
    "            x = (col + x) / grid_w # center position, unit: image width\n",
    "            y = (row + y) / grid_h # center position, unit: image height\n",
    "            w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
    "            h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n",
    "            # last elements are class probabilities\n",
    "            classes = netout[int(row)][col][b][5:]\n",
    "            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "            boxes.append(box)\n",
    "    return boxes\n",
    "\n",
    "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
    "    new_w, new_h = net_w, net_h\n",
    "    for i in range(len(boxes)):\n",
    "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
    "\n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x3\n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "    intersect = intersect_w * intersect_h\n",
    "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "    union = w1*h1 + w2*h2 - intersect\n",
    "    return float(intersect) / union\n",
    "\n",
    "def do_nms(boxes, nms_thresh):\n",
    "    if len(boxes) > 0:\n",
    "        nb_class = len(boxes[0].classes)\n",
    "    else:\n",
    "        return\n",
    "    for c in range(nb_class):\n",
    "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "        for i in range(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "            if boxes[index_i].classes[c] == 0: continue\n",
    "            for j in range(i+1, len(sorted_indices)):\n",
    "                index_j = sorted_indices[j]\n",
    "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "                    boxes[index_j].classes[c] = 0\n",
    "\n",
    "# load and prepare an image\n",
    "def load_image_pixels(filename, shape):\n",
    "    # load the image to get its shape\n",
    "    image = load_img(filename)\n",
    "    width, height = image.size\n",
    "    # load the image with the required size\n",
    "    image = load_img(filename, target_size=shape)\n",
    "    # convert to numpy array\n",
    "    image = img_to_array(image)\n",
    "    # scale pixel values to [0, 1]\n",
    "    image = image.astype('float32')\n",
    "    image /= 255.0\n",
    "    # add a dimension so that we have one sample\n",
    "    image = np.expand_dims(image, 0)\n",
    "    return image, width, height\n",
    "\n",
    "# get all of the results above a threshold\n",
    "def get_boxes(boxes, labels, thresh):\n",
    "    v_boxes, v_labels, v_scores = list(), list(), list()\n",
    "    # enumerate all boxes\n",
    "    for box in boxes:\n",
    "        # enumerate all possible labels\n",
    "        for i in range(len(labels)):\n",
    "            # check if the threshold for this label is high enough\n",
    "            if box.classes[i] > thresh:\n",
    "                v_boxes.append(box)\n",
    "                v_labels.append(labels[i])\n",
    "                v_scores.append(box.classes[i]*100)\n",
    "            # don't break, many labels may trigger for one box\n",
    "    return v_boxes, v_labels, v_scores\n",
    "\n",
    "# draw all results\n",
    "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
    "    # load the image\n",
    "    data = plt.imread(filename)\n",
    "    # plot the image\n",
    "    plt.imshow(data)\n",
    "    # get the context for drawing boxes\n",
    "    ax = plt.gca()\n",
    "    # plot each box\n",
    "    for i in range(len(v_boxes)):\n",
    "        box = v_boxes[i]\n",
    "        # get coordinates\n",
    "        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "        # calculate width and height of the box\n",
    "        width, height = x2 - x1, y2 - y1\n",
    "        # create the shape\n",
    "        rect = plt.Rectangle((x1, y1), width, height, fill=False, color='white')\n",
    "        # draw the box\n",
    "        ax.add_patch(rect)\n",
    "        # draw text and score in top left corner\n",
    "        label = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
    "        plt.text(x1, y1, label, color='white')\n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "source": [
    "## Load model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /Users/haiho/PycharmProjects/yolov3_huynhngocanh/venv/lib/python3.5/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# load yolov3 model\n",
    "model = load_model('yolov3_model.h5')\n",
    "# define the expected input shape for the model\n",
    "input_w, input_h = 416, 416\n",
    "# define the anchors\n",
    "anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
    "# define the probability threshold for detected objects\n",
    "class_threshold = 0.6\n",
    "# define the labels\n",
    "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"airplane\", \"bus\", \"train\", \"truck\",\n",
    "          \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
    "          \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
    "          \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
    "          \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
    "          \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n",
    "          \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "          \"chair\", \"couch\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\n",
    "          \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n",
    "          \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]"
   ]
  },
  {
   "source": [
    "## Gather & concatenate all csv files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "./images/book/529148/1139919.csv\n./images/book/344621/1139063.csv\n./images/book/112798/1985721.csv\n./images/book/385719/1139451.csv\n./images/book/389315/1652379.csv\n./images/book/368684/1145116.csv\n./images/book/506933/1147645.csv\n./images/book/166478/1138070.csv\n./images/book/206579/1986194.csv\n./images/book/96001/1137334.csv\n./images/book/167159/1137818.csv\n./images/book/551439/1140019.csv\n./images/book/16958/1144744.csv\n./images/book/458255/1141588.csv\n./images/book/172617/1140850.csv\n./images/book/334399/1648816.csv\n./images/book/14038/2197005.csv\n./images/book/250901/1986136.csv\n./images/book/25603/1144688.csv\n./images/book/172595/1139612.csv\n./images/book/421923/1137283.csv\n./images/book/222299/1648151.csv\n./images/book/413247/1139762.csv\n./images/book/398377/1138534.csv\n./images/book/509699/1141405.csv\n./images/book/415741/1648882.csv\n./images/book/472678/1648320.csv\n./images/book/575187/1145126.csv\n./images/book/55528/1647877.csv\n./images/book/467176/908400467176.csv\n./images/book/573094/1985088.csv\n./images/book/539883/1138176.csv\n./images/book/553664/1138185.csv\n./images/book/540280/1650976.csv\n./images/book/115870/1141268.csv\n./images/book/479248/1662457.csv\n./images/book/340175/908400340175.csv\n./images/book/400082/1143266.csv\n./images/book/632/1987085.csv\n./images/book/416343/1985126.csv\n./images/book/93353/1137053.csv\n./images/book/71226/1138892.csv\n./images/book/213086/1654376.csv\n./images/book/416451/1658919.csv\n./images/book/194724/1137084.csv\n./images/book/455301/1138815.csv\n./images/book/176232/2143009.csv\n./images/book/24610/1144582.csv\n./images/book/455937/1138668.csv\n./images/book/154705/1649151.csv\n./images/book/123633/1146234.csv\n./images/book/45229/1650257.csv\n./images/book/147518/1985748.csv\n./images/book/136915/1987277.csv\n./images/book/215778/1140731.csv\n./images/book/387098/1983947.csv\n./images/book/134882/1146908.csv\n./images/book/466125/1985068.csv\n./images/book/451308/1984216.csv\n./images/book/58111/1141657.csv\n./images/book/482319/1147472.csv\n./images/book/104666/1140282.csv\n./images/book/121586/1139801.csv\n./images/book/179898/1650038.csv\n./images/book/214224/1654951.csv\n./images/book/473219/1139961.csv\n./images/book/316666/1989379.csv\n./images/book/77396/1136959.csv\n./images/book/547336/1146671.csv\n./images/book/89648/1651552.csv\n./images/book/125129/1983875.csv\n./images/book/36936/2141551.csv\n./images/book/480936/1653080.csv\n./images/book/309938/1139039.csv\n./images/book/323202/1649362.csv\n./images/book/84674/1137165.csv\n./images/book/535253/1985407.csv\n./images/book/255165/1142550.csv\n./images/book/384527/1144024.csv\n./images/book/128148/908400128148.csv\n./images/book/125062/1648577.csv\n./images/book/476810/1147902.csv\n./images/book/567886/1137471.csv\n./images/book/379441/1662278.csv\n./images/book/135872/1138037.csv\n./images/book/179392/1655523.csv\n./images/book/199771/1143506.csv\n./images/book/507575/1140358.csv\n./images/book/39477/1140893.csv\n./images/book/31248/1143403.csv\n./images/book/542776/2196961.csv\n./images/book/308430/1648499.csv\n./images/book/317999/1137617.csv\n./images/book/316015/1657179.csv\n./images/book/262227/1648770.csv\n./images/book/200839/1984132.csv\n./images/book/97994/1142182.csv\n./images/book/205514/1138665.csv\n./images/book/565877/1648063.csv\n./images/book/529568/2141653.csv\n"
     ]
    }
   ],
   "source": [
    "all_files = []\n",
    "cat = 'book'\n",
    "for subdir, dirs, files in os.walk(os.path.join(imageDir,cat)):\n",
    "    for filename in files:\n",
    "        filepath = subdir + os.sep + filename\n",
    "        if filepath.endswith(\".csv\"):\n",
    "            all_files.append(filepath)\n",
    "            print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 bbox category       filename  height                  path  \\\n",
       "0  [271, 117, 36, 23]     book  1139919_0.jpg     140  ./images/book/529148   \n",
       "1    [271, 0, 36, 23]     book  1139919_1.jpg     309  ./images/book/529148   \n",
       "2    [0, 117, 36, 23]     book  1139919_2.jpg     140  ./images/book/529148   \n",
       "3      [0, 0, 36, 23]     book  1139919_3.jpg     309  ./images/book/529148   \n",
       "4  [270, 116, 35, 22]     book    1139919.jpg     426  ./images/book/529148   \n",
       "\n",
       "   width  \n",
       "0    307  \n",
       "1    307  \n",
       "2    369  \n",
       "3    369  \n",
       "4    640  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bbox</th>\n      <th>category</th>\n      <th>filename</th>\n      <th>height</th>\n      <th>path</th>\n      <th>width</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[271, 117, 36, 23]</td>\n      <td>book</td>\n      <td>1139919_0.jpg</td>\n      <td>140</td>\n      <td>./images/book/529148</td>\n      <td>307</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[271, 0, 36, 23]</td>\n      <td>book</td>\n      <td>1139919_1.jpg</td>\n      <td>309</td>\n      <td>./images/book/529148</td>\n      <td>307</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0, 117, 36, 23]</td>\n      <td>book</td>\n      <td>1139919_2.jpg</td>\n      <td>140</td>\n      <td>./images/book/529148</td>\n      <td>369</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[0, 0, 36, 23]</td>\n      <td>book</td>\n      <td>1139919_3.jpg</td>\n      <td>309</td>\n      <td>./images/book/529148</td>\n      <td>369</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[270, 116, 35, 22]</td>\n      <td>book</td>\n      <td>1139919.jpg</td>\n      <td>426</td>\n      <td>./images/book/529148</td>\n      <td>640</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "li = []\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "df_images = pd.concat(li, axis=0, ignore_index=True)\n",
    "df_images.head()"
   ]
  },
  {
   "source": [
    "## Apply prediction to multiple images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(columns=['pred','pred_cat','pred_bbox'])\n",
    "iou_threshold = 0.5\n",
    "for idx, item in df_images.iterrows():\n",
    "    file_path = os.path.join(item['path'], item['filename'])\n",
    "    image, image_w, image_h = load_image_pixels(file_path, (input_w, input_h))\n",
    "    yhat = model.predict(image)\n",
    "    boxes = list()\n",
    "    for i in range(len(yhat)):\n",
    "        # decode the output of the network\n",
    "        boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\n",
    "    # correct the sizes of the bounding boxes for the shape of the image\n",
    "    correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
    "    # suppress non-maximal boxes\n",
    "    do_nms(boxes, 0.5)\n",
    "    # get the details of the detected objects\n",
    "    v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
    "    \n",
    "    ##########\n",
    "    # summarize what we found\n",
    "    # for i in range(len(v_boxes)):\n",
    "    #     print(v_labels[i], v_scores[i])\n",
    "    # draw what we found\n",
    "    # draw_boxes(file_path, v_boxes, v_labels, v_scores)\n",
    "\n",
    "    ##########\n",
    "    boxes = item['bbox'].lstrip(\"[\")\n",
    "    boxes = boxes.rstrip(\"]\")\n",
    "    boxes = boxes.strip()\n",
    "    x, y, w, h = list(map(int,boxes.split(\",\")))\n",
    "    _box = BoundBox(x, y, x+w, y+h)\n",
    "    is_detected = False\n",
    "    for i, box in enumerate(v_boxes): # y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "        # print(bbox_iou(box, _box))\n",
    "        # print(bbox_iou(_box, box))\n",
    "        iou = bbox_iou(box, _box)\n",
    "        if iou > iou_threshold:\n",
    "            df_pred = df_pred.append({\n",
    "                'pred': v_scores[i],\n",
    "                'pred_cat': v_labels[i],\n",
    "                'pred_bbox': [box.xmin, box.ymin, box.xmax-box.xmin, box.ymax-box.ymin]\n",
    "            }, ignore_index=True)\n",
    "            is_detected=True\n",
    "            break\n",
    "    if not is_detected:\n",
    "        df_pred = df_pred.append({\n",
    "            'pred': np.nan,\n",
    "            'pred_cat': np.nan,\n",
    "            'pred_bbox': np.nan\n",
    "        }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 500 entries, 0 to 499\nData columns (total 9 columns):\nbbox         500 non-null object\ncategory     500 non-null object\nfilename     500 non-null object\nheight       500 non-null int64\npath         500 non-null object\nwidth        500 non-null int64\npred         56 non-null float64\npred_cat     56 non-null object\npred_bbox    56 non-null object\ndtypes: float64(1), int64(2), object(6)\nmemory usage: 35.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df_images, df_pred], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 bbox category       filename  height                  path  \\\n",
       "0  [271, 117, 36, 23]     book  1139919_0.jpg     140  ./images/book/529148   \n",
       "1    [271, 0, 36, 23]     book  1139919_1.jpg     309  ./images/book/529148   \n",
       "2    [0, 117, 36, 23]     book  1139919_2.jpg     140  ./images/book/529148   \n",
       "3      [0, 0, 36, 23]     book  1139919_3.jpg     309  ./images/book/529148   \n",
       "4  [270, 116, 35, 22]     book    1139919.jpg     426  ./images/book/529148   \n",
       "\n",
       "   width  pred pred_cat pred_bbox  \n",
       "0    307   NaN      NaN       NaN  \n",
       "1    307   NaN      NaN       NaN  \n",
       "2    369   NaN      NaN       NaN  \n",
       "3    369   NaN      NaN       NaN  \n",
       "4    640   NaN      NaN       NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bbox</th>\n      <th>category</th>\n      <th>filename</th>\n      <th>height</th>\n      <th>path</th>\n      <th>width</th>\n      <th>pred</th>\n      <th>pred_cat</th>\n      <th>pred_bbox</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[271, 117, 36, 23]</td>\n      <td>book</td>\n      <td>1139919_0.jpg</td>\n      <td>140</td>\n      <td>./images/book/529148</td>\n      <td>307</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[271, 0, 36, 23]</td>\n      <td>book</td>\n      <td>1139919_1.jpg</td>\n      <td>309</td>\n      <td>./images/book/529148</td>\n      <td>307</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0, 117, 36, 23]</td>\n      <td>book</td>\n      <td>1139919_2.jpg</td>\n      <td>140</td>\n      <td>./images/book/529148</td>\n      <td>369</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[0, 0, 36, 23]</td>\n      <td>book</td>\n      <td>1139919_3.jpg</td>\n      <td>309</td>\n      <td>./images/book/529148</td>\n      <td>369</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[270, 116, 35, 22]</td>\n      <td>book</td>\n      <td>1139919.jpg</td>\n      <td>426</td>\n      <td>./images/book/529148</td>\n      <td>640</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(imageDir+cat+\"/prediction_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}