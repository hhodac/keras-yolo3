{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Making prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils.bbox import *\n",
    "from utils.colors import *\n",
    "from utils.image import *\n",
    "from utils.utils import *\n",
    "from utils.modelling import *\n",
    "from keras.models import load_model\n",
    "from tensorflow.python.util import deprecation\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "import PIL\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load model & Declare constants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load yolov3 model\n",
    "model = load_model('yolov3_model.h5')\n",
    "# define the expected input shape for the model\n",
    "input_w, input_h = 416, 416\n",
    "# define the anchors\n",
    "anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
    "# define the probability threshold for detected objects\n",
    "class_threshold = 0.6\n",
    "# define the labels\n",
    "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\n",
    "          \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
    "          \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
    "          \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
    "          \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
    "          \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n",
    "          \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "          \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\n",
    "          \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n",
    "          \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictTransformedImage(input_image, shape, model, anchors, class_threshold, labels):\n",
    "    # convert to numpy array\n",
    "    image_w, image_h = input_image.size\n",
    "    resized_image = TF.resize(input_image, shape)\n",
    "    image = img_to_array(resized_image)\n",
    "    # scale pixel values to [0, 1]\n",
    "    image = image.astype('float32')\n",
    "    image /= 255.0\n",
    "    yhat = model.predict(np.expand_dims(image, 0))\n",
    "    boxes = list()\n",
    "    for i in range(len(yhat)):\n",
    "        # decode the output of the network\n",
    "        boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\n",
    "    # correct the sizes of the bounding boxes for the shape of the image\n",
    "    correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
    "    # suppress non-maximal boxes\n",
    "    do_nms(boxes, 0.5)\n",
    "    # get the details of the detected objects\n",
    "    v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
    "    # summarize what we found\n",
    "    for i in range(len(v_boxes)):\n",
    "        print(v_labels[i], v_scores[i])\n",
    "\n",
    "    # plot the image\n",
    "    plt.imshow(input_image)\n",
    "    # get the context for drawing boxes\n",
    "    ax = plt.gca()\n",
    "    # plot each box\n",
    "    for i in range(len(v_boxes)):\n",
    "        box = v_boxes[i]\n",
    "        # get coordinates\n",
    "        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "        # calculate width and height of the box\n",
    "        width, height = x2 - x1, y2 - y1\n",
    "        # create the shape\n",
    "        rect = Rectangle((x1, y1), width, height, fill=False, color='white')\n",
    "        # draw the box\n",
    "        ax.add_patch(rect)\n",
    "        # draw text and score in top left corner\n",
    "        label = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
    "        plt.text(x1, y1, label, color='white')\n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define our new photo\n",
    "photo_filename = './images/dog.jpg'\n",
    "# load and prepare image\n",
    "image, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))\n",
    "# make prediction\n",
    "yhat = model.predict(image)\n",
    "# summarize the shape of the list of arrays\n",
    "print([a.shape for a in yhat])\n",
    "\n",
    "boxes = list()\n",
    "for i in range(len(yhat)):\n",
    "    # decode the output of the network\n",
    "    boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\n",
    "# correct the sizes of the bounding boxes for the shape of the image\n",
    "correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
    "# suppress non-maximal boxes\n",
    "do_nms(boxes, 0.5)\n",
    "# get the details of the detected objects\n",
    "v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
    "# summarize what we found\n",
    "for i in range(len(v_boxes)):\n",
    "    print(v_labels[i], v_scores[i])\n",
    "\n",
    "show_boxes(photo_filename, v_boxes, v_labels, v_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Widget application"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython.core.display import clear_output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Widget 1: show original image\n",
    "\n",
    "PyTorch transformation function list: [link](https://pytorch.org/docs/stable/torchvision/transforms.html)\n",
    "\n",
    "PIL image processing list: [link](https://pytorch.org/docs/stable/torchvision/transforms.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Widget features declaration\n",
    "output_imageOriginal = widgets.Output()\n",
    "output_imageOriginal.layout.border = '1.0px solid'\n",
    "output_imageOriginal.layout.width = 'calc(100% - 14ex)'\n",
    "input_imagePath = widgets.Text(value='./images/dog.jpg', description='Image path')\n",
    "button_imageShow = widgets.Button(description='Show image', button_style='', tooltip='Click to show image')\n",
    "imageOriginal = PIL.Image.open(input_imagePath.value)\n",
    "# Widget function definition\n",
    "def on_imageShowBtn_clicked(_):\n",
    "    global imageOriginal\n",
    "    with output_imageOriginal:\n",
    "        clear_output()\n",
    "        imageOriginal = PIL.Image.open(input_imagePath.value)\n",
    "        print(\"Image size: {}\".format(imageOriginal.size))\n",
    "        display(imageOriginal)\n",
    "\n",
    "button_imageShow.on_click(on_imageShowBtn_clicked)\n",
    "\n",
    "# Grouping widgets\n",
    "box_widget1 = widgets.VBox([ input_imagePath, button_imageShow, output_imageOriginal ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Widget 2: rotate tab"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Widget features declaration\n",
    "slider_rotateAngle = widgets.IntSlider(\n",
    "    value=0, min=-180, max=180, step=1,\n",
    "    description='Angle:',\n",
    "    orientation='horizontal',\n",
    "    readout=True, readout_format='d')\n",
    "button_imageRotate = widgets.Button(description='Rotate', button_style='', tooltip='Click to rotate image')\n",
    "output_imageRotated = widgets.Output()\n",
    "output_imageRotated.layout.border = '1.0px solid'\n",
    "output_imageRotated.layout.width = 'calc(100% - 14ex)'\n",
    "\n",
    "\n",
    "# Widget function definition\n",
    "def on_imageRotateBtn_clicked(_):\n",
    "    global imageRotated\n",
    "    with output_imageRotated:\n",
    "        clear_output()\n",
    "        imageRotated = TF.rotate(\n",
    "            imageOriginal, slider_rotateAngle.value, \n",
    "            resample=PIL.Image.NEAREST, expand=True)\n",
    "        print(\"Rotated image size: {}\".format(imageRotated.size))\n",
    "        display(imageRotated)\n",
    "\n",
    "button_imageRotate.on_click(on_imageRotateBtn_clicked)\n",
    "\n",
    "# Grouping widgets\n",
    "box_widget2 = widgets.VBox([slider_rotateAngle, button_imageRotate, output_imageRotated ])\n",
    "# box_widget2.layout.height = 'calc(50%)'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# rotate tab\n",
    "tab_rotate = widgets.HBox([ box_widget1, box_widget2 ])\n",
    "tab_rotate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Widget 3: crop tab"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# rotate tab\n",
    "tab_crop = widgets.HBox([ box_widget1, box_widget3 ])\n",
    "tab_crop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Widget features declaration\n",
    "slider_cropt = widgets.IntSlider(\n",
    "    value=0, min=0, max=imageOriginal.size[1], step=1,\n",
    "    description='Top:', orientation='horizontal', readout=True, readout_format='d')\n",
    "slider_cropl = widgets.IntSlider(\n",
    "    value=0, min=0, max=imageOriginal.size[0], step=1,\n",
    "    description='Left:', orientation='horizontal', readout=True, readout_format='d')\n",
    "slider_cropw = widgets.IntSlider(\n",
    "    value=imageOriginal.size[0], min=slider_cropl.value, max=imageOriginal.size[0], step=1,\n",
    "    description='Width:', orientation='horizontal', readout=True, readout_format='d')\n",
    "slider_croph = widgets.IntSlider(\n",
    "    value=imageOriginal.size[1], min=slider_cropt.value, max=imageOriginal.size[1], step=1,\n",
    "    description='Height:', orientation='horizontal', readout=True, readout_format='d')\n",
    "box_crop1 = widgets.HBox([ slider_cropl, slider_cropt ])\n",
    "box_crop2 = widgets.HBox([ slider_cropw, slider_croph ])\n",
    "box_crop = widgets.VBox([ box_crop1, box_crop2 ])\n",
    "button_crop = widgets.Button(description='Crop', button_style='', tooltip='Click to crop image')\n",
    "output_imageCropped = widgets.Output()\n",
    "output_imageCropped.layout.border = '1.0px solid'\n",
    "output_imageCropped.layout.width = 'calc(100% - 14ex)'\n",
    "\n",
    "# Widget function definition\n",
    "def on_imageCropBtn_clicked(_):\n",
    "    global imageCropped\n",
    "    with output_imageCropped:\n",
    "        clear_output()\n",
    "        # imageCropped = TF.center_crop(imageOriginal, (slider_croph.value, slider_cropw.value))\n",
    "        imageCropped = TF.crop(imageOriginal, slider_cropt.value, slider_cropl.value, slider_croph.value, slider_cropw.value)\n",
    "        print(\"Rotated image size: {}\".format(imageCropped.size))\n",
    "        display(imageCropped)\n",
    "\n",
    "button_crop.on_click(on_imageCropBtn_clicked)\n",
    "\n",
    "# Grouping widgets\n",
    "box_widget3 = widgets.VBox([box_crop, button_crop, output_imageCropped ])# Widget features declaration\n",
    "slider_cropSize = widgets.IntSlider(\n",
    "    value=0, min=-180, max=180, step=1,\n",
    "    description='Angle:',\n",
    "    orientation='horizontal',\n",
    "    readout=True, readout_format='d')\n",
    "button_imageRotate = widgets.Button(description='Rotate', button_style='', tooltip='Click to rotate image')\n",
    "output_imageRotated = widgets.Output()\n",
    "output_imageRotated.layout.border = '1.0px solid'\n",
    "output_imageRotated.layout.width = 'calc(100% - 14ex)'\n",
    "\n",
    "\n",
    "# Widget function definition\n",
    "def on_imageRotateBtn_clicked(_):\n",
    "    global imageRotated\n",
    "    with output_imageRotated:\n",
    "        clear_output()\n",
    "        imageRotated = TF.rotate(\n",
    "            imageOriginal, slider_rotateAngle.value, \n",
    "            resample=PIL.Image.NEAREST, expand=False)\n",
    "        print(\"Rotated image size: {}\".format(imageRotated.size))\n",
    "        display(imageRotated)\n",
    "\n",
    "button_imageRotate.on_click(on_imageRotateBtn_clicked)\n",
    "\n",
    "# Grouping widgets\n",
    "box_widget2 = widgets.VBox([slider_rotateAngle, button_imageRotate, output_imageRotated ])\n",
    "box_widget2.layout.height = 'calc(50%)'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# defining a list with the contents of our windows\n",
    "children = [tab_rotate, tab_crop]\n",
    "# initializing a tab\n",
    "tab = widgets.Tab()\n",
    "# setting the tab windows \n",
    "tab.children = children\n",
    "# changing the title of the first and second window\n",
    "tab.set_title(0, 'rotate')\n",
    "tab.set_title(1, 'crop')\n",
    "tab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictTransformedImage(imageRotated, (input_w, input_h), model, anchors, class_threshold, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictTransformedImage(imageCropped, (input_w, input_h), model, anchors, class_threshold, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Putting all widgets together"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.5.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}